# -*- coding: utf-8 -*-
"""DHARUN B-Bank Test saturday test (21.05.2022)

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uJwJ_hbEVTwSR7AvhO2I0zKq6X3U74Hr
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd

d=pd.read_csv('/content/bank.csv',delimiter=";")

d

"""**Q1. What does the primary analysis of several categorical
features reveal?**

Administrative staff and technical specialists opened the deposit most of all. In relative terms, a high proportion of pensioners and students might be mentioned as well.       
Although in absolute terms married consumers more often agreed to the service, in relative terms the single was responded better.    
Best communication channel is secullar.        
The difference is evident between consumers who already use the services of banks and received a loan.       
Home ownership does not greatly affect marketing company performance.

**Q2. Perform the following Exploratory Data Analysis tasks:**

a. Missing Value Analysis
"""

d.dropna()

"""b. Label Encoding wherever required"""

from sklearn.preprocessing import LabelEncoder
A = LabelEncoder()
d["job"] = A.fit_transform(d["job"])
d

"""c. Selecting important features based on Random Forest

d. Handling unbalanced data using SMOTE
"""

from sklearn.datasets import make_classification
from collections import Counter
from sklearn.datasets import make_classification
from imblearn.over_sampling import SMOTE
from matplotlib import pyplot
from numpy import where
x, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,
	n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=1)

from collections import Counter
counter = Counter(y)
print(counter)

oversample = SMOTE()
x, y = oversample.fit_resample(x, y)

counter = Counter(y)
print(counter)

for label, _ in counter.items():
	row_ix = where(y == label)[0]
	pyplot.scatter(x[row_ix, 0], x[row_ix, 1], label=str(label))
pyplot.legend()
pyplot.show()

"""e. Standardize the data using the anyone of the scalers
provided by sklearn
"""

t=pd.get_dummies(d)
import numpy as np
h=np.mean(job)/np.std(job)
h

"""**Q3. Build the following Supervised Learning models:**

a. Logistic Regression
"""

from sklearn.linear_model import LogisticRegression

h=LogisticRegression()

from sklearn.model_selection import train_test_split,GridSearchCV,cross_val_score

x1=d.drop(['y'],axis=1).values
y1=d['y'].values

from sklearn.preprocessing import LabelEncoder
l = LabelEncoder()
#assigning numeric value 
d['y'] = l.fit_transform(d['y'])
d

d1=pd.get_dummies(d)

x=d1.drop(['y'],axis=1).values
y=d1['y'].values

from sklearn.model_selection import train_test_split

xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=.20,random_state=0)

from sklearn.linear_model import LogisticRegression

i=LogisticRegression()

i.fit(xtrain,ytrain)

p=i.predict(xtest)
i.predict_proba(xtest)

from sklearn.metrics import accuracy_score,classification_report,confusion_matrix

accuracy_score(ytest,p)

confusion_matrix(ytest,p)

s=classification_report(ytest,p)

print(s)

"""b. AdaBoost

c. Na√Øve Bayes
"""

from sklearn.naive_bayes import GaussianNB

import matplotlib.pyplot as plt
from sklearn.metrics import roc_auc_score,auc
from sklearn.metrics import roc_curve

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.15,random_state=0)

c=GaussianNB()
c.fit(x_train,y_train)

p=c.predict(x_test)

accuracy_score(y_test,p)

z=classification_report(y_test,p)
print(z)

"""d. KNN

"""

from sklearn.neighbors import KNeighborsClassifier

xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=.25,random_state=0)

from sklearn.preprocessing import StandardScaler

s=StandardScaler()

e=KNeighborsClassifier(n_neighbors=5,metric='minkowski',p=2)
e.fit(xtrain,ytrain)

t=e.predict(xtest)

e.predict_proba(xtest)

accuracy_score(ytest,t)

u=classification_report(ytest,t)
print(u)

"""e. SVM

"""

from sklearn.svm import SVC

k=SVC(probability=True)

xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=.20,random_state=0)

k.fit(xtrain,ytrain)

i=k.predict(xtest)

k.predict_proba(xtest)

accuracy_score(ytest,i)

confusion_matrix(ytest,i)

o=classification_report(ytest,i)
print(o)

